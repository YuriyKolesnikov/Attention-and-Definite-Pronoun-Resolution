# Attention-and-Definite-Pronoun-Resolution
### Definite Pronoun Resolution experiment using the Encoder-Decoder model with Attention (TensorFlow)

* In this work, we will try to predict the 2nd (target pronoun), 3rd (two candidate antecedents), 4th (correct antecedent) lines based solely on knowledge of the 1st (the sentence) line from the dataset (http://www.hlt.utdallas.edu/~vince/data/emnlp12/).

* This task can be considered as one of the attempts to evaluate modern achievements in the field of artificial intelligence for understanding common sense inherent only to a reasonable person.

* To solve this problem, I have implemented a language model with an attention mechanism.

* It is a deep learning model that has achieved great success in tasks such as machine translation, text summarization, image annotation, etc.

* I used TensorFlow as a deep learning library. To assess the quality of the model's performance on test data and to understand its level of "Common Sense" relative to a person, I used the BLEU (Bilingual Evaluation Understudy) metric, since it is well suited for evaluating text generated by models based on artificial intelligence, although it is not ideal metric and has several disadvantages.

* As a "baseline" in this task, we will focus on a person's ability to solve such problems and in most cases a person will cope with this task perfectly and his score on the BLEU metric will be 1.0, in the case of a perfect match, while an ideal mismatch leads to a score 0.0.

* The big plus of the Attention mechanism is its interpretability.

* Attention enables us to visualize the neural network's internal attention to training and generated data. In the "Jupyter Notebook" you can study the graphs built for several sentences from the test sample, they clearly show that the model has learned well to identify pronouns and antecedents. Moreover, to determine the antecedent, the model often looks at the context of the sentence with specific conditions that are associated with the correct antecedent.

* After successfully training the model, you can play with different examples from the test data, study the generated sequences of 2, 3, 4 lines and see the visualization of the model's internal attention relative to the selected examples.
